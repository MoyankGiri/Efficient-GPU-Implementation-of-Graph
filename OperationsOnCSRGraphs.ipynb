{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6FjKnTzjBAR",
        "outputId": "91f95903-5da6-441c-b47d-70780088fcc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-0fveh1tz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-0fveh1tz\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rm1zpxb6/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp1e3q6bhq\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/sort.h>\n",
        "#include <thrust/unique.h>\n",
        "#include <thrust/execution_policy.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "struct Edge {\n",
        "    int u, v;\n",
        "    __host__ __device__\n",
        "    Edge(int _u = 0, int _v = 0) : u(_u < _v ? _u : _v), v(_u < _v ? _v : _u) {} // Ensure smaller index first\n",
        "\n",
        "    __host__ __device__\n",
        "    bool operator<(const Edge& other) const {\n",
        "        return u == other.u ? v < other.v : u < other.u;\n",
        "    }\n",
        "\n",
        "    __host__ __device__\n",
        "    bool operator==(const Edge& other) const {\n",
        "        return u == other.u && v == other.v;\n",
        "    }\n",
        "};\n",
        "\n",
        "__global__ void createEdgeList(Edge* edges, int* R, int* C, int num_nodes) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < num_nodes) {\n",
        "        for (int j = R[idx]; j < R[idx + 1]; j++) {\n",
        "            edges[j] = Edge(idx, C[j]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // CSR representation of the graph\n",
        "    int h_R[] = {0, 2, 5, 7, 9};  // Row pointer\n",
        "    int h_C[] = {1, 2, 0, 2, 3, 0, 3, 2, 3};  // Column indices\n",
        "    int num_nodes = sizeof(h_R)/sizeof(h_R[0]) - 1;\n",
        "    int num_edges = sizeof(h_C)/sizeof(h_C[0]);\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    thrust::device_vector<int> R(h_R, h_R + num_nodes + 1);\n",
        "    thrust::device_vector<int> C(h_C, h_C + num_edges);\n",
        "    thrust::device_vector<Edge> edges(num_edges);\n",
        "\n",
        "    // Launch kernel to create edge list\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (num_nodes + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    createEdgeList<<<blocksPerGrid, threadsPerBlock>>>(thrust::raw_pointer_cast(edges.data()), thrust::raw_pointer_cast(R.data()), thrust::raw_pointer_cast(C.data()), num_nodes);\n",
        "\n",
        "    // Sort edges\n",
        "    thrust::sort(thrust::device, edges.begin(), edges.end());\n",
        "\n",
        "    // Remove duplicates\n",
        "    auto it = thrust::unique(thrust::device, edges.begin(), edges.end());\n",
        "    edges.erase(it, edges.end());\n",
        "\n",
        "    // Copy back and print results\n",
        "    std::vector<Edge> output_edges(edges.size());\n",
        "    thrust::copy(edges.begin(), edges.end(), output_edges.begin());\n",
        "    printf(\"Unique edges:\\n\");\n",
        "    for (const auto& edge : output_edges) {\n",
        "        printf(\"{%d, %d}\\n\", edge.u, edge.v);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "AQFQ6olc9WsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717bc63d-53e1-4db4-b997-6c385667864c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique edges:\n",
            "{0, 1}\n",
            "{0, 2}\n",
            "{1, 2}\n",
            "{1, 3}\n",
            "{2, 3}\n",
            "{3, 3}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "// CUDA kernel to remove self-loops from a graph represented in CSR format\n",
        "__global__ void removeSelfLoops(int *rowPtr, int *colIndices, int numVertices) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (tid < numVertices) {\n",
        "        int start = rowPtr[tid];\n",
        "        int end = rowPtr[tid + 1];\n",
        "\n",
        "        // Iterate through the column indices of the current row\n",
        "        for (int i = start; i < end; ++i) {\n",
        "            // If the column index is equal to the current row, it's a self-loop\n",
        "            if (colIndices[i] == tid) {\n",
        "                // Shift elements in colIndices to remove the self-loop\n",
        "                for (int j = i; j < end - 1; ++j) {\n",
        "                    colIndices[j] = colIndices[j + 1];\n",
        "                }\n",
        "                // Decrement the end position since we removed an element\n",
        "                --end;\n",
        "            }\n",
        "        }\n",
        "        // Update the row pointer for the next row\n",
        "        rowPtr[tid + 1] = end;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Example CSR representation of the graph\n",
        "    std::vector<int> rowPtr = {0, 2, 5, 7, 9};  // Row pointer array\n",
        "    std::vector<int> colIndices = {1, 2, 1, 3, 0, 2, 3, 1, 3};  // Column indices array\n",
        "\n",
        "    // Print the original CSR representation\n",
        "    std::cout << \"Original CSR representation:\\n\";\n",
        "    std::cout << \"Row Pointer Array: \";\n",
        "    for (int i : rowPtr) {\n",
        "        std::cout << i << \" \";\n",
        "    }\n",
        "    std::cout << \"\\nColumn Indices Array: \";\n",
        "    for (int i : colIndices) {\n",
        "        std::cout << i << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // Allocate memory on the GPU\n",
        "    int *d_rowPtr, *d_colIndices;\n",
        "    cudaMalloc(&d_rowPtr, rowPtr.size() * sizeof(int));\n",
        "    cudaMalloc(&d_colIndices, colIndices.size() * sizeof(int));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_rowPtr, rowPtr.data(), rowPtr.size() * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_colIndices, colIndices.data(), colIndices.size() * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Calculate number of vertices\n",
        "    int numVertices = rowPtr.size() - 1;\n",
        "\n",
        "    // Define block size and grid size\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (numVertices + blockSize - 1) / blockSize;\n",
        "\n",
        "    // Launch the CUDA kernel\n",
        "    removeSelfLoops<<<gridSize, blockSize>>>(d_rowPtr, d_colIndices, numVertices);\n",
        "\n",
        "    // Copy the results back to host\n",
        "    cudaMemcpy(rowPtr.data(), d_rowPtr, rowPtr.size() * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(colIndices.data(), d_colIndices, colIndices.size() * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the CSR representation after removing self-loops\n",
        "    std::cout << \"\\nCSR representation after removing self-loops:\\n\";\n",
        "    std::cout << \"Row Pointer Array: \";\n",
        "    for (int i : rowPtr) {\n",
        "        std::cout << i << \" \";\n",
        "    }\n",
        "    std::cout << \"\\nColumn Indices Array: \";\n",
        "    for (int i : colIndices) {\n",
        "        std::cout << i << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_rowPtr);\n",
        "    cudaFree(d_colIndices);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "VPq9TdvVpoQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1bc300-2843-424b-89ac-903549ac56ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original CSR representation:\n",
            "Row Pointer Array: 0 2 5 7 9 \n",
            "Column Indices Array: 1 2 1 3 0 2 3 1 3 \n",
            "\n",
            "CSR representation after removing self-loops:\n",
            "Row Pointer Array: 0 2 4 6 8 \n",
            "Column Indices Array: 1 2 3 0 0 3 3 1 3 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// CUDA kernel to remove isolated vertices from a graph in CSR format\n",
        "__global__ void removeIsolatedVerticesKernel(int* d_rowPtr, int* d_colIndices, int sizeCol, int* d_values, int* d_isolated, int numRows, int* d_visited) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    if (tid < numRows) {\n",
        "        if (d_rowPtr[tid] < sizeCol) {\n",
        "            // Vertex tid has neighbors, mark it and its neighbors as not isolated\n",
        "            d_visited[tid] = 1;\n",
        "            for (int j = d_rowPtr[tid]; j < d_rowPtr[tid + 1]; ++j) {\n",
        "                d_visited[d_colIndices[j]] = 1;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to remove isolated vertices from a graph in CSR format using CUDA\n",
        "void removeIsolatedVerticesCUDA(vector<int>& rowPtr, vector<int>& colIndices, vector<int>& values) {\n",
        "    int numRows = rowPtr.size() - 1;\n",
        "    int* d_rowPtr;\n",
        "    int* d_colIndices;\n",
        "    int* d_values;\n",
        "    int* d_isolated;\n",
        "    int* d_visited;\n",
        "    int* visited = new int[numRows];\n",
        "    for (int i = 0; i < numRows; ++i) {\n",
        "        visited[i] = 0; // Initially all vertices are considered isolated\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    cudaMalloc(&d_rowPtr, rowPtr.size() * sizeof(int));\n",
        "    cudaMalloc(&d_colIndices, colIndices.size() * sizeof(int));\n",
        "    cudaMalloc(&d_values, values.size() * sizeof(int));\n",
        "    cudaMalloc(&d_isolated, numRows * sizeof(int));\n",
        "    cudaMalloc(&d_visited, numRows * sizeof(int));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_rowPtr, rowPtr.data(), rowPtr.size() * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_colIndices, colIndices.data(), colIndices.size() * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_values, values.data(), values.size() * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_visited, visited, numRows * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Call kernel to mark isolated vertices\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (numRows + blockSize - 1) / blockSize;\n",
        "    removeIsolatedVerticesKernel<<<numBlocks, blockSize>>>(d_rowPtr, d_colIndices, colIndices.size(), d_values, d_isolated, numRows, d_visited);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copy back isolated vector from device to host\n",
        "    cudaMemcpy(visited, d_visited, numRows * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print adjacency list representation\n",
        "    cout << \"Adjacency list representation:\" << endl;\n",
        "    for (int i = 0; i < numRows; ++i) {\n",
        "        if (visited[i] == 1) {\n",
        "            cout << i << \": \";\n",
        "            for (int j = rowPtr[i]; j < rowPtr[i + 1]; ++j) {\n",
        "                cout << colIndices[j] << \" \";\n",
        "            }\n",
        "            cout << endl;\n",
        "        }\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_rowPtr);\n",
        "    cudaFree(d_colIndices);\n",
        "    cudaFree(d_values);\n",
        "    cudaFree(d_isolated);\n",
        "    cudaFree(d_visited);\n",
        "\n",
        "    delete[] visited;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Example CSR format representation of the graph with an isolated vertex (vertex 4)\n",
        "    vector<int> rowPtr = {0, 2, 5, 7, 8, 8}; // Note: vertex 4 has no neighbors\n",
        "    vector<int> colIndices = {1, 3, 0, 2, 1, 0, 3}; // Only vertex 4 has no connections\n",
        "    vector<int> values = {1, 1, 1, 1, 1, 1, 1};\n",
        "\n",
        "    // Remove isolated vertices using CUDA\n",
        "    removeIsolatedVerticesCUDA(rowPtr, colIndices, values);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceax_4HBtU7B",
        "outputId": "b0ee332c-6596-4fe5-ebca-eb065062e834"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency list representation:\n",
            "0: 1 3 \n",
            "1: 0 2 1 \n",
            "2: 0 3 \n",
            "3: 0 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jl4ZpqVluiAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}