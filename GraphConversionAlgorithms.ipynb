{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RwfISHsu7TI",
        "outputId": "6fe6110f-bfad-4049-a589-8e72d95105c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-w1xmq5sa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-w1xmq5sa\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hz7q0v9o/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp9nueb2qw\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mTPQoMhdu7Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdIK5pWhtKey",
        "outputId": "79abefaa-59d2-42c7-a803-72f2ed534377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "\n",
        "// CUDA kernel for converting CSR to MTX\n",
        "__global__ void csrToMtxKernel(const int *rowPtr, const int *colIdx, const float *values,\n",
        "                               int nnz, int rows, int *outputRow, int *outputCol, float *outputVal) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < nnz) {\n",
        "        int row = 0;\n",
        "        while (rowPtr[row + 1] <= idx) {\n",
        "            row++;\n",
        "        }\n",
        "        outputRow[idx] = row + 1; // 1-based index for MTX\n",
        "        outputCol[idx] = colIdx[idx] + 1; // 1-based index for MTX\n",
        "        outputVal[idx] = values[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "void csrToMtx(const int *rowPtr, const int *colIdx, const float *values, int nnz, int rows) {\n",
        "    int *d_rowPtr, *d_colIdx, *d_outputRow, *d_outputCol;\n",
        "    float *d_values, *d_outputVal;\n",
        "\n",
        "    cudaMalloc(&d_rowPtr, (rows + 1) * sizeof(int));\n",
        "    cudaMalloc(&d_colIdx, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_values, nnz * sizeof(float));\n",
        "    cudaMalloc(&d_outputRow, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_outputCol, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_outputVal, nnz * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_rowPtr, rowPtr, (rows + 1) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_colIdx, colIdx, nnz * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_values, values, nnz * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocks = (nnz + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    csrToMtxKernel<<<blocks, threadsPerBlock>>>(d_rowPtr, d_colIdx, d_values, nnz, rows, d_outputRow, d_outputCol, d_outputVal);\n",
        "\n",
        "    int *outputRow = new int[nnz];\n",
        "    int *outputCol = new int[nnz];\n",
        "    float *outputVal = new float[nnz];\n",
        "    cudaMemcpy(outputRow, d_outputRow, nnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(outputCol, d_outputCol, nnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(outputVal, d_outputVal, nnz * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::ofstream outFile(\"output.mtx\");\n",
        "    outFile << \"%%MatrixMarket matrix coordinate real general\\n\";\n",
        "    outFile << rows << \" \" << rows << \" \" << nnz << \"\\n\";\n",
        "    for (int i = 0; i < nnz; ++i) {\n",
        "        outFile << outputRow[i] << \" \" << outputCol[i] << \" \" << outputVal[i] << \"\\n\";\n",
        "    }\n",
        "    outFile.close();\n",
        "\n",
        "    cudaFree(d_rowPtr);\n",
        "    cudaFree(d_colIdx);\n",
        "    cudaFree(d_values);\n",
        "    cudaFree(d_outputRow);\n",
        "    cudaFree(d_outputCol);\n",
        "    cudaFree(d_outputVal);\n",
        "    delete[] outputRow;\n",
        "    delete[] outputCol;\n",
        "    delete[] outputVal;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int rowPtr[] = {0, 1, 2, 3, 5};\n",
        "    int colIdx[] = {2, 0, 1, 0, 3};\n",
        "    float values[] = {3, 22, 17, 8, 10};\n",
        "    int nnz = 5;\n",
        "    int rows = 4;\n",
        "\n",
        "    csrToMtx(rowPtr, colIdx, values, nnz, rows);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#include <sstream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel to construct the CSR row pointer array\n",
        "__global__ void mtxToCsrKernel(const int *rowIndices, int nnz, int *rowPtr, int rows) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < nnz) {\n",
        "        atomicAdd(&rowPtr[rowIndices[idx] + 1], 1);\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Prefix sum to build the rowPtr array\n",
        "    if (idx == 0) {\n",
        "        for (int i = 1; i <= rows; ++i) {\n",
        "            rowPtr[i] += rowPtr[i - 1];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to parse the MTX file\n",
        "void parseMtxFile(const char *filename, std::vector<int> &rowIndices, std::vector<int> &colIndices, std::vector<float> &values, int &rows, int &cols, int &nnz) {\n",
        "    std::ifstream file(filename);\n",
        "    std::string line;\n",
        "\n",
        "    // Skip headers\n",
        "    while (std::getline(file, line)) {\n",
        "        if (line[0] != '%') break;\n",
        "    }\n",
        "\n",
        "    std::istringstream ss(line);\n",
        "    ss >> rows >> cols >> nnz;\n",
        "\n",
        "    rowIndices.resize(nnz);\n",
        "    colIndices.resize(nnz);\n",
        "    values.resize(nnz);\n",
        "\n",
        "    for (int i = 0; i < nnz; ++i) {\n",
        "        int row, col;\n",
        "        float val;\n",
        "        file >> row >> col >> val;\n",
        "        rowIndices[i] = row - 1; // Adjust for 0-based indexing\n",
        "        colIndices[i] = col - 1;\n",
        "        values[i] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "void mtxToCsr(const char *filename) {\n",
        "    int rows, cols, nnz;\n",
        "    std::vector<int> rowIndices, colIndices;\n",
        "    std::vector<float> values;\n",
        "\n",
        "    parseMtxFile(filename, rowIndices, colIndices, values, rows, cols, nnz);\n",
        "\n",
        "    int *d_rowIndices, *d_colIndices, *d_rowPtr;\n",
        "    float *d_values;\n",
        "    cudaMalloc(&d_rowIndices, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_colIndices, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_values, nnz * sizeof(float));\n",
        "    cudaMalloc(&d_rowPtr, (rows + 1) * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_rowIndices, rowIndices.data(), nnz * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_colIndices, colIndices.data(), nnz * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_values, values.data(), nnz * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMemset(d_rowPtr, 0, (rows + 1) * sizeof(int));\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocks = (nnz + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    mtxToCsrKernel<<<blocks, threadsPerBlock>>>(d_rowIndices, nnz, d_rowPtr, rows);\n",
        "\n",
        "    int *rowPtr = new int[rows + 1];\n",
        "    int *colIndicesOut = new int[nnz];\n",
        "    float *valuesOut = new float[nnz];\n",
        "\n",
        "    cudaMemcpy(rowPtr, d_rowPtr, (rows + 1) * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(colIndicesOut, d_colIndices, nnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(valuesOut, d_values, nnz * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Output the CSR format to verify\n",
        "    std::cout << \"rowPtr: \";\n",
        "    for (int i = 0; i <= rows; ++i) std::cout << rowPtr[i] << \" \";\n",
        "    std::cout << \"\\ncolIdx: \";\n",
        "    for (int i = 0; i < nnz; ++i) std::cout << colIndicesOut[i] << \" \";\n",
        "    std::cout << \"\\nvalues: \";\n",
        "    for (int i = 0; i < nnz; ++i) std::cout << valuesOut[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    cudaFree(d_rowIndices);\n",
        "    cudaFree(d_colIndices);\n",
        "    cudaFree(d_values);\n",
        "    cudaFree(d_rowPtr);\n",
        "    delete[] rowPtr;\n",
        "    delete[] colIndicesOut;\n",
        "    delete[] valuesOut;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const char *filename = \"output.mtx\";\n",
        "    mtxToCsr(filename);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypo-1rnRvNMV",
        "outputId": "761b73f3-63ee-43e7-9150-2ccfa0363dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rowPtr: 0 1 2 3 5 \n",
            "colIdx: 2 0 1 0 3 \n",
            "values: 3 22 17 8 10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <algorithm>\n",
        "\n",
        "// Kernel to count the number of non-zero elements per column\n",
        "__global__ void countNonZerosPerColumn(const int *colIdx, int nnz, int *colCount) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < nnz) {\n",
        "        atomicAdd(&colCount[colIdx[idx]], 1);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel to compute column pointers (cumulative sum)\n",
        "__global__ void computeColPtr(int *colCount, int *colPtr, int cols) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx == 0) {\n",
        "        colPtr[0] = 0;\n",
        "        for (int i = 1; i <= cols; ++i) {\n",
        "            colPtr[i] = colPtr[i - 1] + colCount[i - 1];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel to rearrange data to CSC format\n",
        "__global__ void rearrangeToCSC(const int *rowPtr, const int *colIdx, const float *values, int nnz,\n",
        "                               int *rowIndicesCSC, float *valuesCSC, int *colPtr) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < nnz) {\n",
        "        int col = colIdx[idx];\n",
        "        int dstIdx = atomicAdd(&colPtr[col], 1);\n",
        "        rowIndicesCSC[dstIdx] = rowPtr[idx];\n",
        "        valuesCSC[dstIdx] = values[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "void csrToCsc(const int *rowPtr, const int *colIdx, const float *values, int rows, int cols, int nnz) {\n",
        "    int *d_rowPtr, *d_colIdx, *d_colCount, *d_colPtr, *d_rowIndicesCSC;\n",
        "    float *d_values, *d_valuesCSC;\n",
        "\n",
        "    // Allocate memory on the GPU\n",
        "    cudaMalloc(&d_rowPtr, (rows + 1) * sizeof(int));\n",
        "    cudaMalloc(&d_colIdx, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_values, nnz * sizeof(float));\n",
        "    cudaMalloc(&d_colCount, cols * sizeof(int));\n",
        "    cudaMalloc(&d_colPtr, (cols + 1) * sizeof(int));\n",
        "    cudaMalloc(&d_rowIndicesCSC, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_valuesCSC, nnz * sizeof(float));\n",
        "\n",
        "    // Copy CSR data to the GPU\n",
        "    cudaMemcpy(d_rowPtr, rowPtr, (rows + 1) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_colIdx, colIdx, nnz * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_values, values, nnz * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMemset(d_colCount, 0, cols * sizeof(int));\n",
        "\n",
        "    // Count non-zeros per column\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocks = (nnz + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    countNonZerosPerColumn<<<blocks, threadsPerBlock>>>(d_colIdx, nnz, d_colCount);\n",
        "\n",
        "    // Compute column pointers (exclusive scan)\n",
        "    computeColPtr<<<1, 1>>>(d_colCount, d_colPtr, cols);\n",
        "\n",
        "    // Rearrange data to CSC\n",
        "    rearrangeToCSC<<<blocks, threadsPerBlock>>>(d_rowPtr, d_colIdx, d_values, nnz, d_rowIndicesCSC, d_valuesCSC, d_colPtr);\n",
        "\n",
        "    // Copy results back to the host for verification\n",
        "    int *rowIndicesCSC = new int[nnz];\n",
        "    float *valuesCSC = new float[nnz];\n",
        "    int *colPtr = new int[cols + 1];\n",
        "    cudaMemcpy(rowIndicesCSC, d_rowIndicesCSC, nnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(valuesCSC, d_valuesCSC, nnz * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(colPtr, d_colPtr, (cols + 1) * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Output the CSC representation for verification\n",
        "    std::cout << \"colPtr: \";\n",
        "    for (int i = 0; i <= cols; ++i) std::cout << colPtr[i] << \" \";\n",
        "    std::cout << \"\\nrowIdx: \";\n",
        "    for (int i = 0; i < nnz; ++i) std::cout << rowIndicesCSC[i] << \" \";\n",
        "    std::cout << \"\\nvalues: \";\n",
        "    for (int i = 0; i < nnz; ++i) std::cout << valuesCSC[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // Free allocated memory\n",
        "    cudaFree(d_rowPtr);\n",
        "    cudaFree(d_colIdx);\n",
        "    cudaFree(d_values);\n",
        "    cudaFree(d_colCount);\n",
        "    cudaFree(d_colPtr);\n",
        "    cudaFree(d_rowIndicesCSC);\n",
        "    cudaFree(d_valuesCSC);\n",
        "    delete[] rowIndicesCSC;\n",
        "    delete[] valuesCSC;\n",
        "    delete[] colPtr;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int rowPtr[] = {0, 1, 2, 3, 5};\n",
        "    int colIdx[] = {2, 0, 1, 0, 3};\n",
        "    float values[] = {3, 22, 17, 8, 10};\n",
        "    int nnz = 5;\n",
        "    int rows = 4, cols = 4;\n",
        "\n",
        "    csrToCsc(rowPtr, colIdx, values, rows, cols, nnz);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5QOLPRPyz4M",
        "outputId": "e36ebf87-8bfd-431e-eed8-81e5b8390d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colPtr: 2 3 4 5 5 \n",
            "rowIdx: 1 3 2 0 5 \n",
            "values: 22 8 17 3 10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "// Kernel to count the number of non-zero elements per row\n",
        "__global__ void countNonZerosPerRow(const int *rowIdx, int nnz, int *rowCount) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < nnz) {\n",
        "        atomicAdd(&rowCount[rowIdx[idx]], 1);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel to compute row pointers (cumulative sum)\n",
        "__global__ void computeRowPtr(int *rowCount, int *rowPtr, int rows) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx == 0) {\n",
        "        rowPtr[0] = 0;\n",
        "        for (int i = 1; i <= rows; ++i) {\n",
        "            rowPtr[i] = rowPtr[i - 1] + rowCount[i - 1];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel to rearrange data to CSR format\n",
        "__global__ void rearrangeToCSR(const int *colPtr, const int *rowIdx, const float *values, int nnz,\n",
        "                               int *colIndicesCSR, float *valuesCSR, int *rowPtr) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < nnz) {\n",
        "        int row = rowIdx[idx];\n",
        "        int dstIdx = atomicAdd(&rowPtr[row], 1);\n",
        "        colIndicesCSR[dstIdx] = colPtr[idx];\n",
        "        valuesCSR[dstIdx] = values[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "void cscToCsr(const int *colPtr, const int *rowIdx, const float *values, int rows, int cols, int nnz) {\n",
        "    int *d_colPtr, *d_rowIdx, *d_rowCount, *d_rowPtr, *d_colIndicesCSR;\n",
        "    float *d_values, *d_valuesCSR;\n",
        "\n",
        "    // Allocate memory on the GPU\n",
        "    cudaMalloc(&d_colPtr, (cols + 1) * sizeof(int));\n",
        "    cudaMalloc(&d_rowIdx, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_values, nnz * sizeof(float));\n",
        "    cudaMalloc(&d_rowCount, rows * sizeof(int));\n",
        "    cudaMalloc(&d_rowPtr, (rows + 1) * sizeof(int));\n",
        "    cudaMalloc(&d_colIndicesCSR, nnz * sizeof(int));\n",
        "    cudaMalloc(&d_valuesCSR, nnz * sizeof(float));\n",
        "\n",
        "    // Copy CSC data to the GPU\n",
        "    cudaMemcpy(d_colPtr, colPtr, (cols + 1) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_rowIdx, rowIdx, nnz * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_values, values, nnz * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMemset(d_rowCount, 0, rows * sizeof(int));\n",
        "\n",
        "    // Count non-zeros per row\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocks = (nnz + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    countNonZerosPerRow<<<blocks, threadsPerBlock>>>(d_rowIdx, nnz, d_rowCount);\n",
        "\n",
        "    // Compute row pointers (exclusive scan)\n",
        "    computeRowPtr<<<1, 1>>>(d_rowCount, d_rowPtr, rows);\n",
        "\n",
        "    // Rearrange data to CSR\n",
        "    rearrangeToCSR<<<blocks, threadsPerBlock>>>(d_colPtr, d_rowIdx, d_values, nnz, d_colIndicesCSR, d_valuesCSR, d_rowPtr);\n",
        "\n",
        "    // Copy results back to the host for verification\n",
        "    int *rowPtr = new int[rows + 1];\n",
        "    int *colIndicesCSR = new int[nnz];\n",
        "    float *valuesCSR = new float[nnz];\n",
        "    cudaMemcpy(rowPtr, d_rowPtr, (rows + 1) * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(colIndicesCSR, d_colIndicesCSR, nnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(valuesCSR, d_valuesCSR, nnz * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Output the CSR representation for verification\n",
        "    std::cout << \"rowPtr: \";\n",
        "    for (int i = 0; i <= rows; ++i) std::cout << rowPtr[i] << \" \";\n",
        "    std::cout << \"\\ncolIdx: \";\n",
        "    for (int i = 0; i < nnz; ++i) std::cout << colIndicesCSR[i] << \" \";\n",
        "    std::cout << \"\\nvalues: \";\n",
        "    for (int i = 0; i < nnz; ++i) std::cout << valuesCSR[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // Free allocated memory\n",
        "    cudaFree(d_colPtr);\n",
        "    cudaFree(d_rowIdx);\n",
        "    cudaFree(d_values);\n",
        "    cudaFree(d_rowCount);\n",
        "    cudaFree(d_rowPtr);\n",
        "    cudaFree(d_colIndicesCSR);\n",
        "    cudaFree(d_valuesCSR);\n",
        "    delete[] rowPtr;\n",
        "    delete[] colIndicesCSR;\n",
        "    delete[] valuesCSR;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int colPtr[] = {0, 2, 3, 4, 5};\n",
        "    int rowIdx[] = {1, 3, 2, 0, 3};\n",
        "    float values[] = {22, 8, 17, 3, 10};\n",
        "    int nnz = 5;\n",
        "    int rows = 4, cols = 4;\n",
        "\n",
        "    cscToCsr(colPtr, rowIdx, values, rows, cols, nnz);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0krF_RtqzxUp",
        "outputId": "4edc2e4f-92dc-428a-eceb-b141c3ec0516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rowPtr: 1 2 3 5 5 \n",
            "colIdx: 4 0 3 2 5 \n",
            "values: 3 22 17 8 10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wd10WCa60IJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}